<!DOCTYPE html>

<html lang="en">

<head>

    <!-- Metadata -->
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="website" />
    <meta name="author" content="Md Ashiqur Rahman" />
    <title>Md Ashiqur Rahman | phd cs @ Purdue</title>
    <link rel="icon" type="image/x-icon" href="assets/img/mandu_icon.png" />

    <!-- Font Awesome icons -->
    <script src="https://use.fontawesome.com/releases/v5.15.3/js/all.js"></script>

    <!-- Google fonts-->
    --
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link
        href="https://fonts.googleapis.com/css2?family=Merriweather:wght@300;400;700;900&family=Roboto:wght@300;400;500;700&family=Fira+Code&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/assets/owl.carousel.min.css">
    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/assets/owl.theme.default.min.css">

    <!-- Core theme CSS -->
    <link href="styles/styles.css" rel="stylesheet" />
    <link href="styles/affiliations_fix.css" rel="stylesheet" />

</head>

<body class="light-theme">

    <!-- Moving particles -->
    <canvas id="canvas"></canvas>

    <!-- Progress bar on top -->
    <div class="progress-bar-container">
        <div class="progress-bar" id="progressBar"></div>
    </div>

    <!-- Back to top button -->
    <a id="back-to-top-button"></a>

    <!-- Assitant icon saying about theme changes -->
    <div class="popup-icon-container" id="popupIconContainer" draggable="true">
        <div class="icon"><img src="assets/img/mandu_icon.png" width="65" height="65"></div>
        <div class="speech-balloon"></div>
    </div>

    <!-- Dismissal area for assistant icon -->
    <div class="dismissal-area" id="dismissalArea">&#10006;</div>

    <!-- Side Navigation bar -->
    <!-- Fusion of jQuery slidebar (https://codepen.io/BeshoyRomany/pen/qmNPwN) and animated hamburger menu (https://codepen.io/amberweinberg/pen/yeqJgG) -->
    <nav class="side-nav">
        <a class="nav-toggle-btn" onclick="toggleNav()" style="display: none;">
            <span></span>
            <span></span>
            <span></span>
        </a>
        <ul>
            <li>
                <p onclick="scrollToTopDiv('html')"><span class="nav-icon"><i class="fas fa-home"></i></span> <span
                        class="text">home</span></p>
            </li>
            <li>
                <p onclick="scrollToTopDiv('#updates')"><span class="nav-icon"><i class="fas fa-newspaper"></i></span>
                    <span class="text">updates</span>
                </p>
            </li>
            <li>
                <p onclick="scrollToTopDiv('#research')"><span class="nav-icon"><i
                            class="fas fa-graduation-cap"></i></span> <span class="text">publications</span></p>
            </li>
            <li>
                <p onclick="scrollToTopDiv('#outreach')"><span class="nav-icon"><i class="fas fa-users"></i></span>
                    <span class="text">outreach</span>
                </p>
            </li>
            <li>
                <p onclick="scrollToTopDiv('#resources')"><span class="nav-icon"><i class="fas fa-tools"></i></span>
                    <span class="text">resources</span>
                </p>
            </li>
            <!-- <li><p onclick="scrollToTopDiv('#gallery')"><span class="nav-icon"><i class="fas fa-images"></i></span> <span class="text">gallery</span></p></li> -->
        </ul>
    </nav>

    <!-- Content -->
    <div class="container" style="padding-top: 1.5rem;">
        <!-- About section -->

        <div class="row mb-4">
            <div class="col-lg-2 col-md-4">
                <div class="ring-container">
                    <div class="ring">
                        <div class="hollow-ring">
                            <img class="profile-image" src="assets/img/profile_pic_3.jpeg" alt="Md Ashiqur Rahman" />

                            <div class="emoji-indicator">
                                ‚òØÔ∏è <span class="hover-text"> </span>
                            </div>

                        </div>
                    </div>
                </div>
                <hr />
                <div class="social-icons">
                    <a class="social-icon" href="https://scholar.google.com/citations?user=isCWj28AAAAJ&amp;hl=en"
                        target="_blank" rel="noopener" title="Google Scholar"><i class="fa fa-graduation-cap"
                            style="font-size: 35px; color: #4285f4"></i></a>

                    <a class="social-icon" href="https://github.com/ashiq24" target="_blank" rel="noopener"
                        title="GitHub"><i class="fab fa-github" style="font-size: 35px; color: #171515"></i></a>

                    <a class="social-icon" href="assets/doc/cv_ashiq.pdf" target="_blank" rel="noopener"
                        title="Resume/CV"><i class="fas fa-id-card" style="font-size: 35px; color: #bd5d38"></i></a>
                </div>
                <div class="social-icons">


                    <a class="social-icon" onclick="scrollToTopDiv('#research');" title="Projects"><i
                            class="fa fa-shapes" style="font-size: 35px; color: #e8828c"></i></a>

                    <a class="social-icon" id="contact-card-trigger" title="Contact Info"><i class="fa fa-id-card"
                            style="font-size: 35px; color: #cbbb5f"></i></a>
                    <a class="social-icon"
                        href="https://docs.google.com/forms/d/e/1FAIpQLScwlxkoM-ZuKhDk3nZvk70MGKirSne6BH3Y_zlkMLJxHLRMRw/viewform?usp=dialog"
                        target="_blank" rel="noopener" title="Anonymous Feedback">
                        <img src="assets/img/anon-msg-badge.svg" alt="Anonymous Message"
                            style="width: 35px; height: 35px; border-radius: 6px;">
                    </a>
                </div>
                <p></p>
            </div>

            <!-- Inspired by Thanh Tran -- https://codepen.io/thanhrossi/pen/pvOEzq -->
            <!-- Re-written, redesigned, and integrated (from HTML (Pug) and CSS (Less) to pure HTML and CSS) -->
            <div class="contact-card-overlay" id="overlay-bg">
                <div class="information_card">
                    <div id="front_end_card">
                        <div class="front">
                            <div class="contact-info-card">
                                <div class="code-line"><span class="line-number">1</span><span
                                        class="code-content"><span class="keyword">class</span> <span
                                            class="namespace">ContactInformationCard</span>: </span></div>
                                <div class="code-line"><span class="line-number">2</span><span class="code-content">
                                        <span class="keyword">def</span> <span class="function">__init__</span>(<span
                                            class="self">self</span>):</span></div>
                                <div class="code-line"><span class="line-number">3</span><span class="code-content">
                                        <span class="self">self</span>.<span class="self">dept</span> = <span
                                            class="string">"cs @ Purdue"</span> </span></div>
                                <div class="code-line"><span class="line-number">4</span><span class="code-content">
                                        <span class="self">self</span>.<span class="self">lab</span> = <span
                                            class="string">""</span> </span></div>
                                <div class="code-line"><span class="line-number">5</span><span class="code-content">
                                        <span class="self">self</span>.<span class="self">email</span> = <span
                                            class="string">"rahman79@purdue.edu"</span> </span></div>
                                <div class="code-line"><span class="line-number">6</span><span class="code-content">
                                        <span class="self">self</span>.<span class="self">phone</span> = <span
                                            class="string">""</span> </span></div>
                                <div class="code-line"><span class="line-number">7</span><span
                                        class="code-content"></span></div>
                                <div class="code-line"><span class="line-number">8</span><span class="code-content">
                                        <span class="keyword">def</span> <span class="function">flipCard</span>(<span
                                            class="self">self</span>):</span></div>
                                <div class="code-line"><span class="line-number">9</span><span class="code-content">
                                        <span class="function">print</span>(<span class="string">"tap on the card to
                                            flip."</span>)</span></div>
                                <div class="code-line"><span class="line-number">10</span><span
                                        class="code-content"></span></div>
                                <div class="code-line"><span class="line-number">11</span><span class="code-content">
                                        <span class="keyword">def</span> <span class="function">closeCard</span>(<span
                                            class="self">self</span>):</span></div>
                                <div class="code-line"><span class="line-number">12</span><span class="code-content">
                                        <span class="function">print</span>(<span class="string">"tap outside to close
                                            it."</span>)</span></div>
                            </div>
                        </div>
                        <div class="back">
                            <div class="contact-info-card">
                                <p class="card-name">Md Ashiqur Rahman</p>
                                <a href="" target="_blank" rel="noopener" class="card-website-link" title="Website"></a>
                            </div>
                        </div>

                    </div>
                </div>
            </div>

            <div class="col-lg-10 col-md-8">
                <h2>
                    Md Ashiqur Rahman
                    <span class="text-primary"> /√¶ É…™k/ </span>
                    <span id="volumeEmoji" role="button"> üéß </span>
                </h2>
                <p></p>
                I am Md Ashiqur Rahman, a fourth-year Ph.D. student in Computer Science at Purdue University, guided by
                Professor Raymond A. Yeh. My research is primarily focused on the development of robust machine learning
                models, particularly in the areas of equivariance and geometric machine learning, as well as exploring
                the applications of AI in scientific discovery.
                <p></p>
                I earned my Bachelor's degree in Computer Science and Engineering from the Bangladesh University of
                Engineering and Technology (BUET). I am passionate about advancing the field of computer science and am
                always open to discussions and collaborations. Thank you for visiting my page!
                <p></p>
                <div class="codebox">
                    My research unifies geometric principles, signal processing techniques, and equivariance theory to
                    develop more robust and consistent AI systems.
                    <p></p>

                    <b>Computer Vision:</b> Geometric Deep Learning, Equivariant Neural Networks, Generative Models
                    <br />

                    <b>Operator Learning:</b> Solving PDEs, Scientific Machine Learning
                    <br />

                </div>
            </div>
        </div>

        <!-- Affiliations section -->

        <hr />

        <div class="row" id="affiliations">
            <div class="col">
                <h2 clss="mb-5">üèõÔ∏è Affiliations</h2>
                <p></p>
                <div class="owl-carousel owl-theme affiliations-carousel">

                    <div class="affiliation-card">
                        <div class="affiliation-image-container">
                            <img src="assets/img/updates_fig/purdue_logo.png" class="affiliation-image"
                                alt="PhD, Purdue University" />
                        </div>
                        <div class="affiliation-content">
                            <h5 class="affiliation-institution">PhD, Purdue University</h5>
                            <p class="affiliation-period">2021 - Present</p>
                        </div>
                    </div>


                    <div class="affiliation-card">
                        <div class="affiliation-image-container">
                            <img src="assets/img/updates_fig/autodesk_1.png" class="affiliation-image"
                                alt="Autodesk Research" />
                        </div>
                        <div class="affiliation-content">
                            <h5 class="affiliation-institution">Autodesk Research</h5>
                            <p class="affiliation-period">Summer 2025</p>
                        </div>
                    </div>


                    <div class="affiliation-card">
                        <div class="affiliation-image-container">
                            <img src="assets/img/updates_fig/Nvidia-Logo.png" class="affiliation-image"
                                alt="NVIDIA Research" />
                        </div>
                        <div class="affiliation-content">
                            <h5 class="affiliation-institution">NVIDIA Research</h5>
                            <p class="affiliation-period">Summer 2023</p>
                        </div>
                    </div>


                    <div class="affiliation-card">
                        <div class="affiliation-image-container">
                            <img src="assets/img/updates_fig/buet_logo.png" class="affiliation-image"
                                alt="Bangladesh University of Engineering and Technology" />
                        </div>
                        <div class="affiliation-content">
                            <h5 class="affiliation-institution">Bangladesh University of Engineering and Technology</h5>
                            <p class="affiliation-period">2015 - 2019</p>
                        </div>
                    </div>


                </div>
                <p></p>
            </div>
        </div>

        <!-- Updates section -->

        <hr />

        <div class="row" id="updates">
            <div class="col">
                <h2 clss="mb-5">üìú Updates</h2>
                <p></p>
                <div class="owl-carousel owl-theme">

                    <div class="news-card">
                        <img src="assets/img/updates_fig/iccv.png" class="w-full rounded-lg" />
                        <div class="news-desc">Two papers accepted at <hightlight>ICCV 2025</hightlight>!</div>
                        <div class="news-time">Aug 2025</div>
                    </div>

                    <div class="news-card">
                        <img src="assets/img/updates_fig/autodesk_1.png" class="w-full rounded-lg" />
                        <div class="news-desc">I will spend my summer as AI Research Intern at <hightlight>Autodesk
                            </hightlight>!</div>
                        <div class="news-time">May 2025</div>
                    </div>

                    <div class="news-card">
                        <img src="assets/img/updates_fig/iclr_png_singa.png" class="w-full rounded-lg" />
                        <div class="news-desc">I will attend ICLR 2025 in <hightlight>Singapore</hightlight>.</div>
                        <div class="news-time">April 2025</div>
                    </div>

                    <div class="news-card">
                        <img src="assets/img/updates_fig/confernec.png" class="w-full rounded-lg" />
                        <div class="news-desc">I will attend NeurIPS 2024 in <hightlight>Vancouver, Canada</hightlight>.
                        </div>
                        <div class="news-time">December 2024</div>
                    </div>

                </div>
                <p></p>
            </div>
        </div>

        <!-- Research section -->

        <hr />

        <div class="row" id="research">
            <div class="col">
                <h2 clss="mb-5">üìö Publications</h2>
                <p></p>
                <div id="filters-project">
                    <button class="filter-button active" data-filter="*">all</button>

                    <button class="filter-button" data-filter="Equivariance">Equivariance</button>

                    <button class="filter-button" data-filter="Neural Operator">Neural Operator</button>

                    <button class="filter-button" data-filter="Bioinformatics">Bioinformatics</button>

                </div>
                <p></p>
                <div id="projects" class="isotope">

                    <div class="project publication-card" data-filter="Equivariance">
                        <div class="row mb-4">
                            <div class="col-sm-4">
                                <img width="100%" height="auto" class="w-full rounded-lg"
                                    src="assets/img/paper_fig/clip_sym.png" />
                            </div>
                            <div class="col-sm-8">
                                <div class="publication-content">
                                    <div class="publication-header">

                                        <h4 class="publication-title">CLIPSym: Delving into Symmetry Detection with CLIP
                                        </h4>
                                    </div>

                                    <div class="publication-meta">
                                        <i><a href="" target="_blank" rel="noopener" class="conference-link">ICCV
                                                2025</a></i>

                                    </div>

                                    <div class="publication-authors">Tinghan Yang, <u>Md Ashiqur Rahman</u>, Raymond A.
                                        Yeh</div>

                                    <div class="publication-links">
                                        <a href="https://arxiv.org/pdf/2508.14197" target="_blank" rel="noopener"
                                            class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a>
                                        <a href="https://github.com/timyoung2333/CLIPSym" target="_blank" rel="noopener"
                                            class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a>






                                    </div>

                                    <div class="publication-abstract">
                                        <span class="abstract-label">Abstract:</span>
                                        Symmetry is one of the most fundamental geometric cues in computer vision, and
                                        detecting it has been an ongoing challenge.
                                        <span class="collapse" id="more_equivariance">
                                            With the recent advances in vision-language models,~i.e., CLIP, we
                                            investigate whether a pre-trained CLIP model can aid symmetry detection by
                                            leveraging the additional symmetry cues found in the natural image
                                            descriptions. We propose CLIPSym, which leverages CLIP's image and language
                                            encoders and a rotation-equivariant decoder based on a hybrid of Transformer
                                            and G-Convolution to detect rotation and reflection symmetries. To fully
                                            utilize CLIP's language encoder, we have developed a novel prompting
                                            technique called Semantic-Aware Prompt Grouping (SAPG), which aggregates a
                                            diverse set of frequent object-based prompts to better integrate the
                                            semantic cues for symmetry detection. Empirically, we show that CLIPSym
                                            outperforms the current state-of-the-art on three standard symmetry
                                            detection datasets (DENDI, SDRW, and LDRS). Finally, we conduct detailed
                                            ablations verifying the benefits of CLIP's pre-training, the proposed
                                            equivariant decoder, and the SAPG technique.
                                        </span>
                                        <span> <a href="#more_equivariance" data-toggle="collapse"
                                                onclick="toggleText(this)" id="link-more_equivariance"
                                                class="abstract-toggle">... See More</a></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>


                    <div class="project publication-card" data-filter="Equivariance">
                        <div class="row mb-4">
                            <div class="col-sm-4">
                                <img width="100%" height="auto" class="w-full rounded-lg"
                                    src="assets/img/paper_fig/local_scale_logo.png" />
                            </div>
                            <div class="col-sm-8">
                                <div class="publication-content">
                                    <div class="publication-header">

                                        <h4 class="publication-title">Local Scale Equivariance with Latent Deep
                                            Equilibrium Canonicalizer</h4>
                                    </div>

                                    <div class="publication-meta">
                                        <i><a href="" target="_blank" rel="noopener" class="conference-link">ICCV
                                                2025</a></i>

                                    </div>

                                    <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Chiao-An Yang, Michael N.
                                        Cheng, Lim Jun Hao, Jeremiah Jiang, Teck-Yian Lim, Raymond A. Yeh</div>

                                    <div class="publication-links">
                                        <a href="https://arxiv.org/pdf/2508.14187" target="_blank" rel="noopener"
                                            class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a>
                                        <a href="https://github.com/ashiq24/local-scale-equivariance" target="_blank"
                                            rel="noopener" class="btn-link btn-code"><i class="fab fa-github"></i>
                                            CODE</a>
                                        <a href="https://ashiq24.github.io/local-scale-equivariance/" target="_blank"
                                            rel="noopener" class="btn-link btn-website"><i
                                                class="fas fa-external-link-alt"></i> WEBSITE</a>





                                    </div>

                                    <div class="publication-abstract">
                                        <span class="abstract-label">Abstract:</span>
                                        Scale variation is a fundamental challenge in computer vision. Objects of the
                                        same class can have different sizes
                                        <span class="collapse" id="more_equivariance">
                                            and their perceived size is further affected by the distance from the
                                            camera. These variations are local to the objects, i.e., different object
                                            sizes may change differently within the same image. To effectively handle
                                            scale variations, we present a deep equilibrium canonicalizer (DEC) to
                                            improve the local scale equivariance of a model. DEC can be easily
                                            incorporated into existing network architectures and can be adapted to a
                                            pre-trained model. Notably, we show that on the competitive ImageNet
                                            benchmark, DEC improves both model performance and local scale consistency
                                            across four popular pre-trained deep-nets, e.g., ViT, DeiT, Swin, and BEiT.
                                        </span>
                                        <span> <a href="#more_equivariance" data-toggle="collapse"
                                                onclick="toggleText(this)" id="link-more_equivariance"
                                                class="abstract-toggle">... See More</a></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>


                    <div class="project publication-card" data-filter="Equivariance">
                        <div class="row mb-4">
                            <div class="col-sm-4">
                                <img width="100%" height="auto" class="w-full rounded-lg"
                                    src="assets/img/paper_fig/group_dwn.jpg" />
                            </div>
                            <div class="col-sm-8">
                                <div class="publication-content">
                                    <div class="publication-header">

                                        <h4 class="publication-title">Group Downsampling with Equivariant Anti-aliasing
                                        </h4>
                                    </div>

                                    <div class="publication-meta">
                                        <i><a href="" target="_blank" rel="noopener" class="conference-link">ICLR
                                                2025</a></i>

                                    </div>

                                    <div class="publication-authors"><u>Md Ashiqur Rahman</u>, and Raymond A. Yeh.</div>

                                    <div class="publication-links">
                                        <a href="https://openreview.net/pdf?id=sOte83GogU" target="_blank"
                                            rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i>
                                            PDF</a>
                                        <a href="https://github.com/ashiq24/Group_Sampling" target="_blank"
                                            rel="noopener" class="btn-link btn-code"><i class="fab fa-github"></i>
                                            CODE</a>

                                        <a href="https://colab.research.google.com/drive/1Fkuid94wnVltsgwOblvbuGaVMjLl1YCr?usp=sharing"
                                            target="_blank" rel="noopener" class="btn-link btn-demo"><i
                                                class="fas fa-play-circle"></i> DEMO</a>



                                        <a href="https://huggingface.co/blog/ashiq24/group-sampling" target="_blank"
                                            rel="noopener" class="btn-link btn-tutorial"><i
                                                class="fas fa-book-open"></i> TUTORIAL</a>
                                    </div>

                                    <div class="publication-abstract">
                                        <span class="abstract-label">Abstract:</span>
                                        Downsampling layers are crucial building blocks in CNN architectures, which help
                                        to increase the receptive field for learning high-level features and reduce the
                                        amount of memory/computation in the model.
                                        <span class="collapse" id="more_equivariance">
                                            In this work, we study the generalization of the uniform downsampling layer
                                            for group equivariant architectures, e.g., $G$-CNNs. That is, we aim to
                                            downsample signals (feature maps) on general finite groups with
                                            anti-aliasing. This involves the following (a) Given a finite group and a
                                            downsampling rate, we present an algorithm to form a suitable choice of
                                            subgroup. (b) Given a group and a subgroup, we study the notion of
                                            bandlimited-ness and propose how to perform anti-aliasing. Notably, our
                                            method generalizes the notion of downsampling based on classical sampling
                                            theory. When the signal is on a cyclic group, i.e., periodic, our method
                                            recovers the standard downsampling of an ideal low-pass filter followed by a
                                            subsampling operation. Finally, we conducted experiments on image
                                            classification tasks demonstrating that the proposed downsampling operation
                                            improves accuracy, better preserves equivariance, and reduces model size
                                            when incorporated into $G$-equivariant networks.
                                        </span>
                                        <span> <a href="#more_equivariance" data-toggle="collapse"
                                                onclick="toggleText(this)" id="link-more_equivariance"
                                                class="abstract-toggle">... See More</a></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>


                    <div class="project publication-card" data-filter="Neural Operator">
                        <div class="row mb-4">
                            <div class="col-sm-4">
                                <img width="100%" height="auto" class="w-full rounded-lg"
                                    src="assets/img/paper_fig/codano.png" />
                            </div>
                            <div class="col-sm-8">
                                <div class="publication-content">
                                    <div class="publication-header">

                                        <h4 class="publication-title">Pretraining Codomain Attention Neural Operators
                                            for Solving Multiphysics PDEs.</h4>
                                    </div>

                                    <div class="publication-meta">
                                        <i><a href="" target="_blank" rel="noopener" class="conference-link">NeurIPS
                                                2024</a></i>

                                    </div>

                                    <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Robert Joseph George,
                                        Mogab Elleithy, Daniel Leibovici, Zongyi Li, Boris Bonev, Colin White, Julius
                                        Berner, Raymond A. Yeh, Jean Kossaifi, Kamyar Azizzadenesheli, Anima Anandkumar
                                    </div>

                                    <div class="publication-links">
                                        <a href="https://arxiv.org/pdf/2403.12553" target="_blank" rel="noopener"
                                            class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a>
                                        <a href="https://github.com/neuraloperator/CoDA-NO" target="_blank"
                                            rel="noopener" class="btn-link btn-code"><i class="fab fa-github"></i>
                                            CODE</a>

                                        <a href="https://colab.research.google.com/drive/1W6Qy5Mk_vEjZgrA0tWMespXqKEYDOdc6?usp=sharing"
                                            target="_blank" rel="noopener" class="btn-link btn-demo"><i
                                                class="fas fa-play-circle"></i> DEMO</a>




                                    </div>

                                    <div class="publication-abstract">
                                        <span class="abstract-label">Abstract:</span>
                                        Existing neural operator architectures face challenges when solving multiphysics
                                        problems with coupled partial differential equations (PDEs), due to complex
                                        geometries,
                                        <span class="collapse" id="more_neural_operator">
                                            interactions between physical variables, and the lack of large amounts of
                                            high-resolution training data. To address these issues, we propose Codomain
                                            Attention Neural Operator (CoDA-NO), which tokenizes functions along the
                                            codomain or channel space, enabling self-supervised learning or pretraining
                                            of multiple PDE systems. Specifically, we extend positional encoding,
                                            self-attention, and normalization layers to the function space. CoDA-NO can
                                            learn representations of different PDE systems with a single model. We
                                            evaluate CoDA-NO's potential as a backbone for learning multiphysics PDEs
                                            over multiple systems by considering few-shot learning settings. On complex
                                            downstream tasks with limited data, such as fluid flow simulations and
                                            fluid-structure interactions, we found CoDA-NO to outperform existing
                                            methods on the few-shot learning task by over 36%.
                                        </span>
                                        <span> <a href="#more_neural_operator" data-toggle="collapse"
                                                onclick="toggleText(this)" id="link-more_neural_operator"
                                                class="abstract-toggle">... See More</a></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>


                    <div class="project publication-card" data-filter="Equivariance">
                        <div class="row mb-4">
                            <div class="col-sm-4">
                                <img width="100%" height="auto" class="w-full rounded-lg"
                                    src="assets/img/paper_fig/scale_eq.png" />
                            </div>
                            <div class="col-sm-8">
                                <div class="publication-content">
                                    <div class="publication-header">

                                        <h4 class="publication-title">Truly Scale-Equivariant Deep Nets with Fourier
                                            Layers.</h4>
                                    </div>

                                    <div class="publication-meta">
                                        <i><a href="" target="_blank" rel="noopener" class="conference-link">NeurIPS
                                                2023</a></i>

                                    </div>

                                    <div class="publication-authors"><u>Md Ashiqur Rahman</u>, and Raymond A. Yeh.</div>

                                    <div class="publication-links">
                                        <a href="https://arxiv.org/pdf/2311.02922" target="_blank" rel="noopener"
                                            class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a>
                                        <a href="https://github.com/ashiq24/Scale_Equivarinat_Fourier_Layer/"
                                            target="_blank" rel="noopener" class="btn-link btn-code"><i
                                                class="fab fa-github"></i> CODE</a>

                                        <a href="https://colab.research.google.com/drive/1fKHxYw1QxJ1CWpDFGLdl8Im83GnfAbFC?usp=sharing"
                                            target="_blank" rel="noopener" class="btn-link btn-demo"><i
                                                class="fas fa-play-circle"></i> DEMO</a>


                                        <a href="https://ashiq24.github.io/scale_equivariant_fourier_layer/resource/poster_thumb.pdf"
                                            target="_blank" rel="noopener" class="btn-link btn-poster"><i
                                                class="fas fa-image"></i> POSTER</a>

                                    </div>

                                    <div class="publication-abstract">
                                        <span class="abstract-label">Abstract:</span>
                                        In computer vision, models must be able to adapt to changes in image resolution
                                        to effectively carry out tasks such as image segmentation
                                        <span class="collapse" id="more_equivariance">
                                            ; This is known as scale-equivariance. Recent works have made progress in
                                            developing scale-equivariant convolutional neural networks, e.g., through
                                            weight-sharing and kernel resizing. However, these networks are not truly
                                            scale-equivariant in practice. Specifically, they do not consider
                                            anti-aliasing as they formulate the down-scaling operation in the continuous
                                            domain. To address this shortcoming, we directly formulate down-scaling in
                                            the discrete domain with consideration of anti-aliasing. We then propose a
                                            novel architecture based on Fourier layers to achieve truly
                                            scale-equivariant deep nets, i.e., absolute zero equivariance-error.
                                            Following prior works, we test this model on MNIST-scale and STL-10
                                            datasets. Our proposed model achieves competitive classification performance
                                            while maintaining zero equivariance-error.
                                        </span>
                                        <span> <a href="#more_equivariance" data-toggle="collapse"
                                                onclick="toggleText(this)" id="link-more_equivariance"
                                                class="abstract-toggle">... See More</a></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>


                    <div class="project publication-card" data-filter="Neural Operator">
                        <div class="row mb-4">
                            <div class="col-sm-4">
                                <img width="100%" height="auto" class="w-full rounded-lg"
                                    src="assets/img/paper_fig/uno.png" />
                            </div>
                            <div class="col-sm-8">
                                <div class="publication-content">
                                    <div class="publication-header">

                                        <h4 class="publication-title">U-NO: U-shaped Neural Operators</h4>
                                    </div>

                                    <div class="publication-meta">
                                        <i><a href="" target="_blank" rel="noopener"
                                                class="conference-link">Transactions on Machine Learning Research
                                                2023</a></i>

                                    </div>

                                    <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Zachary E. Ross, Kamyar
                                        Azizzadenesheli.</div>

                                    <div class="publication-links">
                                        <a href="https://openreview.net/pdf?id=j3oQF9coJd" target="_blank"
                                            rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i>
                                            PDF</a>
                                        <a href="https://github.com/ashiq24/UNO" target="_blank" rel="noopener"
                                            class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a>

                                        <a href="https://colab.research.google.com/drive/1f1WYsjAgIjJRFtfQYYnZCZsxl602MMPX?usp=sharing"
                                            target="_blank" rel="noopener" class="btn-link btn-demo"><i
                                                class="fas fa-play-circle"></i> DEMO</a>




                                    </div>

                                    <div class="publication-abstract">
                                        <span class="abstract-label">Abstract:</span>
                                        Neural operators generalize classical neural networks to maps between
                                        infinite-dimensional spaces, e.g., function spaces.
                                        <span class="collapse" id="more_neural_operator">
                                            Prior works on neural operators proposed a series of novel methods to learn
                                            such maps and demonstrated unprecedented success in learning solution
                                            operators of partial differential equations. Due to their close proximity to
                                            fully connected architectures, these models mainly suffer from high memory
                                            usage and are generally limited to shallow deep learning models. In this
                                            paper, we propose U-shaped Neural Operator (U-NO), a U-shaped memory
                                            enhanced architecture that allows for deeper neural operators. U-NOs exploit
                                            the problem structures in function predictions and demonstrate fast
                                            training, data efficiency, and robustness with respect to hyperparameters
                                            choices. We study the performance of U-NO on PDE benchmarks, namely, Darcy's
                                            flow law and the Navier-Stokes equations. We show that U-NO results in an
                                            average of 26% and 44% prediction improvement on Darcy's flow and turbulent
                                            Navier-Stokes equations, respectively, over the state of the art. On
                                            Navier-Stokes 3D spatiotemporal operator learning task, we show U-NO
                                            provides 37\% improvement over the state of art methods.
                                        </span>
                                        <span> <a href="#more_neural_operator" data-toggle="collapse"
                                                onclick="toggleText(this)" id="link-more_neural_operator"
                                                class="abstract-toggle">... See More</a></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>


                    <div class="project publication-card" data-filter="Neural Operator">
                        <div class="row mb-4">
                            <div class="col-sm-4">
                                <img width="100%" height="auto" class="w-full rounded-lg"
                                    src="assets/img/paper_fig/gano.jpg" />
                            </div>
                            <div class="col-sm-8">
                                <div class="publication-content">
                                    <div class="publication-header">

                                        <h4 class="publication-title">Generative Adversarial Neural Operators.</h4>
                                    </div>

                                    <div class="publication-meta">
                                        <i><a href="" target="_blank" rel="noopener"
                                                class="conference-link">Transactions on Machine Learning Research
                                                2022</a></i>

                                    </div>

                                    <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Manuel A. Florez, Anima
                                        Anandkumar, Zachary E. Ross, Kamyar Azizzadenesheli.</div>

                                    <div class="publication-links">
                                        <a href="https://openreview.net/pdf?id=X1VzbBU6xZ" target="_blank"
                                            rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i>
                                            PDF</a>
                                        <a href="https://github.com/neuraloperator/GANO" target="_blank" rel="noopener"
                                            class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a>






                                    </div>

                                    <div class="publication-abstract">
                                        <span class="abstract-label">Abstract:</span>
                                        We propose the generative adversarial neural operator (GANO), a generative model
                                        paradigm for learning probabilities on infinite-dimensional function spaces.
                                        <span class="collapse" id="more_neural_operator">
                                            The natural sciences and engineering are known to have many types of data
                                            that are sampled from infinite-dimensional function spaces, where classical
                                            finite-dimensional deep generative adversarial networks (GANs) may not be
                                            directly applicable. GANO generalizes the GAN framework and allows for the
                                            sampling of functions by learning push-forward operator maps in
                                            infinite-dimensional spaces. GANO consists of two main components, a
                                            generator neural operator and a discriminator neural functional. The inputs
                                            to the generator are samples of functions from a user-specified probability
                                            measure, e.g., Gaussian random field (GRF), and the generator outputs are
                                            synthetic data functions. The input to the discriminator is either a real or
                                            synthetic data function. In this work, we instantiate GANO using the
                                            Wasserstein criterion and show how the Wasserstein loss can be computed in
                                            infinite-dimensional spaces. We empirically study GANO in controlled cases
                                            where both input and output functions are samples from GRFs and compare its
                                            performance to the finite-dimensional counterpart GAN. We empirically study
                                            the efficacy of GANO on real-world function data of volcanic activities and
                                            show its superior performance over GAN.
                                        </span>
                                        <span> <a href="#more_neural_operator" data-toggle="collapse"
                                                onclick="toggleText(this)" id="link-more_neural_operator"
                                                class="abstract-toggle">... See More</a></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>


                    <div class="project publication-card" data-filter="Neural Operator">
                        <div class="row mb-4">
                            <div class="col-sm-4">
                                <img width="100%" height="auto" class="w-full rounded-lg"
                                    src="assets/img/paper_fig/pacmo.jpg" />
                            </div>
                            <div class="col-sm-8">
                                <div class="publication-content">
                                    <div class="publication-header">

                                        <h4 class="publication-title">PaCMO: Partner Dependent Human Motion Generation
                                            in Dyadic Human Activity using Neural Operators.</h4>
                                    </div>

                                    <div class="publication-meta">
                                        <i><a href="" target="_blank" rel="noopener" class="conference-link">ArXiv
                                                2022</a></i>

                                    </div>

                                    <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Jasorsi Ghosh, Hrishikesh
                                        Viswanath, Kamyar Azizzadenesheli, Aniket Bera.</div>

                                    <div class="publication-links">
                                        <a href="https://arxiv.org/pdf/2211.16210" target="_blank" rel="noopener"
                                            class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a>







                                    </div>

                                    <div class="publication-abstract">
                                        <span class="abstract-label">Abstract:</span>
                                        We address the problem of generating 3D human motions in dyadic activities. In
                                        contrast to the concurrent works, which mainly focus on
                                        <span class="collapse" id="more_neural_operator">
                                            generating the motion of a single actor from the textual description, we
                                            generate the motion of one of the actors from the motion of the other
                                            participating actor in the action. This is a particularly challenging,
                                            under-explored problem, that requires learning intricate relationships
                                            between the motion of two actors participating in an action and also
                                            identifying the action from the motion of one actor. To address these, we
                                            propose partner conditioned motion operator (PaCMO), a neural operator-based
                                            generative model which learns the distribution of human motion conditioned
                                            by the partner's motion in function spaces through adversarial training. Our
                                            model can handle long unlabeled action sequences at arbitrary time
                                            resolution. We also introduce the "Functional Frechet Inception Distance"
                                            (F2ID) metric for capturing similarity between real and generated data for
                                            function spaces. We test PaCMO on NTU RGB+D and DuetDance datasets and our
                                            model produces realistic results evidenced by the F2ID score and the
                                            conducted user study.
                                        </span>
                                        <span> <a href="#more_neural_operator" data-toggle="collapse"
                                                onclick="toggleText(this)" id="link-more_neural_operator"
                                                class="abstract-toggle">... See More</a></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>


                    <div class="project publication-card" data-filter="Bioinformatics">
                        <div class="row mb-4">
                            <div class="col-sm-4">
                                <img width="100%" height="auto" class="w-full rounded-lg"
                                    src="assets/img/paper_fig/beene.jpeg" />
                            </div>
                            <div class="col-sm-8">
                                <div class="publication-content">
                                    <div class="publication-header">

                                        <h4 class="publication-title">BEENE: Deep Learning-based Nonlinear Embedding
                                            Improves Batch Effect Estimation.BEENE: Deep Learning-based Nonlinear
                                            Embedding Improves Batch Effect Estimation.</h4>
                                    </div>

                                    <div class="publication-meta">
                                        <i><a href="https://academic.oup.com/bioinformatics" target="_blank"
                                                rel="noopener" class="conference-link">Bioinformatics, Volume 39,
                                                2023</a></i>

                                    </div>

                                    <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Abdullah Aman Tutul,
                                        Mahfuza Sharmin, Md Shamsuzzoha Bayzid</div>

                                    <div class="publication-links">
                                        <a href="https://academic.oup.com/bioinformatics/article/39/8/btad479/7240486?login=false"
                                            target="_blank" rel="noopener" class="btn-link btn-pdf"><i
                                                class="fas fa-file-pdf"></i> PDF</a>
                                        <a href="https://github.com/ashiq24/BEENE" target="_blank" rel="noopener"
                                            class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a>






                                    </div>

                                    <div class="publication-abstract">
                                        <span class="abstract-label">Abstract:</span>
                                        Analyzing large-scale single-cell transcriptomic datasets generated using
                                        different technologies is challenging due to the presence of batch-specific
                                        systematic variations known as batch effects.
                                        <span class="collapse" id="more_bioinformatics">
                                            Since biological and technological differences are often interspersed,
                                            detecting and accounting for batch effects in RNA-seq datasets are critical
                                            for effective data integration and interpretation. Low-dimensional
                                            embeddings, such as principal component analysis (PCA) are widely used in
                                            visual inspection and estimation of batch effects. Linear dimensionality
                                            reduction methods like PCA are effective in assessing the presence of batch
                                            effects, especially when batch effects exhibit linear patterns. However,
                                            batch effects are inherently complex and existing linear dimensionality
                                            reduction methods could be inadequate and imprecise in the presence of
                                            sophisticated nonlinear batch effects. Results:- We present Batch Effect
                                            Estimation using Nonlinear Embedding (BEENE), a deep nonlinear auto-encoder
                                            network which is specially tailored to generate an alternative lower
                                            dimensional embedding suitable for both linear and nonlinear batch effects.
                                            BEENE simultaneously learns the batch and biological variables from RNA-seq
                                            data, resulting in an embedding that is more robust and sensitive than PCA
                                            embedding in terms of detecting and quantifying batch effects. BEENE was
                                            assessed on a collection of carefully controlled simulated datasets as well
                                            as biological datasets, including two technical replicates of mouse
                                            embryogenesis cells, peripheral blood mononuclear cells from three largely
                                            different experiments and five studies of pancreatic islet cells
                                        </span>
                                        <span> <a href="#more_bioinformatics" data-toggle="collapse"
                                                onclick="toggleText(this)" id="link-more_bioinformatics"
                                                class="abstract-toggle">... See More</a></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>


                    <div class="project publication-card" data-filter="Bioinformatics">
                        <div class="row mb-4">
                            <div class="col-sm-4">
                                <img width="100%" height="auto" class="w-full rounded-lg"
                                    src="assets/img/paper_fig/chapao.jpg" />
                            </div>
                            <div class="col-sm-8">
                                <div class="publication-content">
                                    <div class="publication-header">

                                        <h4 class="publication-title">CHAPAO: Likelihood and hierarchical
                                            reference-based representation of biomolecular sequences and applications to
                                            compressing multiple sequence alignments.</h4>
                                    </div>

                                    <div class="publication-meta">
                                        <i><a href="https://journals.plos.org/plosone/" target="_blank" rel="noopener"
                                                class="conference-link">PLOS ONE 2022</a></i>

                                    </div>

                                    <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Abdullah Aman Tutul,
                                        Sifat Muhammad Abdullah, Md. Shamsuzzoha Bayzid.</div>

                                    <div class="publication-links">
                                        <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0265360"
                                            target="_blank" rel="noopener" class="btn-link btn-pdf"><i
                                                class="fas fa-file-pdf"></i> PDF</a>
                                        <a href="https://github.com/ashiq24/CHAPAO" target="_blank" rel="noopener"
                                            class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a>






                                    </div>

                                    <div class="publication-abstract">
                                        <span class="abstract-label">Abstract:</span>
                                        High-throughput experimental technologies are generating tremendous amounts of
                                        genomic data, offering valuable resources to answer important questions and
                                        extract biological insights. Storing this sheer amount of genomic data has
                                        become a major concern in bioinformatics.
                                        <span class="collapse" id="more_bioinformatics">
                                            General purpose compression techniques (e.g. gzip, bzip2, 7-zip) are being
                                            widely used due to their pervasiveness and relatively good speed. However,
                                            they are not customized for genomic data and may fail to leverage special
                                            characteristics and redundancy of the biomolecular sequences. Results:- We
                                            present a new lossless compression method CHAPAO (COmpressing Alignments
                                            using Hierarchical and Probabilistic Approach), which is especially designed
                                            for multiple sequence alignments (MSAs) of biomolecular data and offers very
                                            good compression gain. We have introduced a novel hierarchical referencing
                                            technique to represent biomolecular sequences which combines likelihood
                                            based analyses of the sequence similarities and graph theoretic algorithms.
                                            We performed an extensive evaluation study using a collection of real
                                            biological data from the avian phylogenomics project, 1000 plants project
                                            (1KP), and 16S and 23S rRNA datasets. We report the performance of CHAPAO in
                                            comparison with general purpose compression techniques as well as with
                                            MFCompress and Nucleotide Archival Format (NAF)‚Äîtwo of the best known
                                            methods especially designed for FASTA files. Experimental results suggest
                                            that CHAPAO offers significant improvements in compression gain over most
                                            other alternative methods.
                                        </span>
                                        <span> <a href="#more_bioinformatics" data-toggle="collapse"
                                                onclick="toggleText(this)" id="link-more_bioinformatics"
                                                class="abstract-toggle">... See More</a></span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>


                </div>
                <p></p>
            </div>
        </div>

        <!-- Outreach section

<hr>
<div class="row" id="outreach">
    <div class="col">
        <h2 clss="mb-5">üß© Outreach Activities</h2>
        <p></p>
        
        <p></p>
    </div>
</div> -->

        <!-- Resources section -->

        <hr />

        <div class="row" id="resources">
            <div class="col">
                <h2 clss="mb-5">‚õèÔ∏è Resources</h2>
                <p></p>
                all software releases of the above projects can also be found here!
                <p></p>
                <div id="filters-resources">
                    <button class="filter-button active" data-filter="*">all</button>

                    <button class="filter-button" data-filter="research">research</button>

                    <button class="filter-button" data-filter="misc">miscellaneous</button>

                    <button class="filter-button" data-filter="Open Source">open-source</button>

                </div>
                <p></p>
                <div id="github-cards">

                    <div class="github-card" data-filter="research">
                        <div data-url="https://api.github.com/repos/neuraloperator/CoDA-NO"></div>
                    </div>


                    <div class="github-card" data-filter="open-source">
                        <div data-url="https://api.github.com/repos/neuraloperator/neuraloperator"></div>
                    </div>


                    <div class="github-card" data-filter="research">
                        <div data-url="https://api.github.com/repos/ashiq24/Scale_Equivarinat_Fourier_Layer"></div>
                    </div>


                    <div class="github-card" data-filter="research">
                        <div data-url="https://api.github.com/repos/ashiq24/UNO"></div>
                    </div>


                    <div class="github-card" data-filter="research">
                        <div data-url="https://api.github.com/repos/ashiq24/BEENE"></div>
                    </div>


                    <div class="github-card" data-filter="open-source">
                        <div data-url="https://api.github.com/repos/ashiq24/Copula"></div>
                    </div>


                    <div class="github-card" data-filter="miscellaneous">
                        <div data-url="https://api.github.com/repos/ashiq24/Python-Tool-to-Visualize-Fractals"></div>
                    </div>


                </div>
                <p></p>
            </div>
        </div>

        <!-- Gallery section -->

        <!-- <hr>
<div class="row" id="gallery">
    <div class="col">
        <h2 clss="mb-5">üñºÔ∏è Gallery</h2>
        <p></p>
        
        <p></p>
        
        <p></p>
    </div>
</div> -->

        <!-- Footer section -->

        <div>‚Äé</div>
        <footer class="pt-2 my-md-2 pt-md-">
            <div class="row justify-content-center">
                <div class="col-7 col-md text-left align-self-center">
                    <p class="h6">¬© Md Ashiqur Rahman, 2025</p>
                    <a href="https://github.com/mkhangg/academic-website" target="_blank" rel="noopener"><b>&gt; web
                            source @github</b></a>
                </div>
                <div class="col col-md text-right">
                    <div class="footer-logos">

                    </div>
                </div>
            </div>
            <p></p>
        </footer>


    </div>

    <!-- Bootstrap core JS-->
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Isotope JS -->
    <script src="https://cdn.jsdelivr.net/npm/isotope-layout@3.0.2/dist/isotope.pkgd.min.js"></script>

    <!-- OwlCarousel2 JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/owl.carousel.min.js"></script>

    <!-- Axios JS -->
    <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>

    <!-- Third party plugin JS-->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js"></script>

    <!-- Core theme JS-->
    <script src="js/scripts.js"></script>

</body>

</html>