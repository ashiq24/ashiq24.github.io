<!DOCTYPE html>

<html lang="en">
    <head>

        <!-- Metadata -->
        <meta charset="utf-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/>
        <meta name="description" content="website"/>
        <meta name="author" content="Md Ashiqur Rahman"/>
        <title>Md Ashiqur Rahman | phd cs @ Purdue</title>
        <link rel="icon" type="image/x-icon" href="assets/img/mandu_icon.png"/>
        
        <!-- Font Awesome icons -->
        <script src="https://use.fontawesome.com/releases/v5.15.3/js/all.js"></script>
		
        <!-- Google fonts-->
        -- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css"/>
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css"/>
        <link href="https://fonts.googleapis.com/css2?family=Fira+Code&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/assets/owl.carousel.min.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/assets/owl.theme.default.min.css">

        <!-- Core theme CSS -->
        <link href="styles/styles.css" rel="stylesheet"/>
        <link href="styles/affiliations_fix.css" rel="stylesheet"/>

    </head>

    <body class="light-theme">

        <!-- Moving particles -->
        <canvas id="canvas"></canvas>

        <!-- Progress bar on top -->
        <div class="progress-bar-container">
            <div class="progress-bar" id="progressBar"></div>
        </div>

        <!-- Back to top button -->
        <a id="back-to-top-button"></a>

        <!-- Assitant icon saying about theme changes -->
        <div class="popup-icon-container" id="popupIconContainer" draggable="true">
            <div class="icon"><img src="assets/img/mandu_icon.png" width="65" height="65"></div>
            <div class="speech-balloon"></div>
        </div>
        
        <!-- Dismissal area for assistant icon -->
        <div class="dismissal-area" id="dismissalArea">&#10006;</div>

        <!-- Side Navigation bar -->
        <!-- Fusion of jQuery slidebar (https://codepen.io/BeshoyRomany/pen/qmNPwN) and animated hamburger menu (https://codepen.io/amberweinberg/pen/yeqJgG) -->
        <nav class="side-nav">
            <a class="nav-toggle-btn" onclick="toggleNav()" style="display: none;">
                <span></span>
                <span></span>
                <span></span>
            </a>
            <ul>
                <li><p onclick="scrollToTopDiv('html')"><span class="nav-icon"><i class="fas fa-home"></i></span> <span class="text">home</span></p></li>
                <li><p onclick="scrollToTopDiv('#updates')"><span class="nav-icon"><i class="fas fa-newspaper"></i></span> <span class="text">updates</span></p></li>
                <li><p onclick="scrollToTopDiv('#research')"><span class="nav-icon"><i class="fas fa-graduation-cap"></i></span> <span class="text">publications</span></p></li>
                <li><p onclick="scrollToTopDiv('#outreach')"><span class="nav-icon"><i class="fas fa-users"></i></span> <span class="text">outreach</span></p></li>
                <li><p onclick="scrollToTopDiv('#resources')"><span class="nav-icon"><i class="fas fa-tools"></i></span> <span class="text">resources</span></p></li>
                <!-- <li><p onclick="scrollToTopDiv('#gallery')"><span class="nav-icon"><i class="fas fa-images"></i></span> <span class="text">gallery</span></p></li> -->
            </ul>
        </nav>

        <!-- Content -->
        <div class="container" style="padding-top: 1.5rem;">
            <!-- About section -->

<div class="row mb-4">
    <div class="col-lg-2 col-md-4">
        <div class="ring-container">
            <div class="ring">
                <div class="hollow-ring">
                    <img class="profile-image" src="assets/img/profile_pic_3.jpeg" alt="Md Ashiqur Rahman" />
                     
                        <div class="emoji-indicator">
                            ‚òØÔ∏è <span class="hover-text">  </span> 
                        </div> 
                    
                </div>
            </div>
        </div>
        <hr />
        <div class="social-icons">
             <a class="social-icon" href="https://scholar.google.com/citations?user=isCWj28AAAAJ&amp;hl=en" target="_blank" rel="noopener" title="Google Scholar"><i class="fa fa-graduation-cap" style="font-size: 35px; color: #4285f4"></i></a> 
            
             <a class="social-icon" href="https://github.com/ashiq24" target="_blank" rel="noopener" title="GitHub"><i class="fab fa-github" style="font-size: 35px; color: #171515"></i></a> 
            
             <a class="social-icon" href="assets/doc/cv_ashiq.pdf" target="_blank" rel="noopener" title="Resume"><i class="fas fa-file-alt" style="font-size: 35px; color: #bd5d38"></i></a> 
        </div>
        <div class="social-icons">
            
            
             <a class="social-icon" onclick="scrollToTopDiv('#research');" title="Projects"><i class="fa fa-shapes" style="font-size: 35px; color: #e8828c"></i></a> 
            
             <a class="social-icon" id="contact-card-trigger" title="Contact Info"><i class="fa fa-id-card" style="font-size: 35px; color: #cbbb5f"></i></a> 
        </div>
        <p></p>
    </div>

    <!-- Inspired by Thanh Tran -- https://codepen.io/thanhrossi/pen/pvOEzq -->
    <!-- Re-written, redesigned, and integrated (from HTML (Pug) and CSS (Less) to pure HTML and CSS) -->
    <div class="contact-card-overlay" id="overlay-bg">
        <div class="information_card">
            <div id="front_end_card">
                <div class="front">
                    <div class="contact-info-card">
                        <div class="code-line"><span class="line-number">1</span><span class="code-content"><span class="keyword">class</span> <span class="namespace">ContactInformationCard</span>: </span></div>
                        <div class="code-line"><span class="line-number">2</span><span class="code-content">  <span class="keyword">def</span> <span class="function">__init__</span>(<span class="self">self</span>):</span></div>
                        <div class="code-line"><span class="line-number">3</span><span class="code-content">    <span class="self">self</span>.<span class="self">dept</span>  = <span class="string">"cs @ Purdue"</span> </span></div>
                        <div class="code-line"><span class="line-number">4</span><span class="code-content">    <span class="self">self</span>.<span class="self">lab</span>   = <span class="string">""</span> </span></div>
                        <div class="code-line"><span class="line-number">5</span><span class="code-content">    <span class="self">self</span>.<span class="self">email</span> = <span class="string">"rahman79@purdue.edu"</span> </span></div>
                        <div class="code-line"><span class="line-number">6</span><span class="code-content">    <span class="self">self</span>.<span class="self">phone</span> = <span class="string">""</span> </span></div>
                        <div class="code-line"><span class="line-number">7</span><span class="code-content"></span></div>
                        <div class="code-line"><span class="line-number">8</span><span class="code-content">  <span class="keyword">def</span> <span class="function">flipCard</span>(<span class="self">self</span>):</span></div>
                        <div class="code-line"><span class="line-number">9</span><span class="code-content">    <span class="function">print</span>(<span class="string">"tap on the card to flip."</span>)</span></div>
                        <div class="code-line"><span class="line-number">10</span><span class="code-content"></span></div>
                        <div class="code-line"><span class="line-number">11</span><span class="code-content">  <span class="keyword">def</span> <span class="function">closeCard</span>(<span class="self">self</span>):</span></div>
                        <div class="code-line"><span class="line-number">12</span><span class="code-content">    <span class="function">print</span>(<span class="string">"tap outside to close it."</span>)</span></div>
                    </div>
                </div>
                <div class="back">
                    <div class="contact-info-card">
                        <p class="card-name">Md Ashiqur Rahman</p>
                        <a href="" target="_blank" rel="noopener" class="card-website-link" title="Website"></a>
                    </div>
                </div>

            </div>
        </div>
    </div>

    <div class="col-lg-10 col-md-8">
        <h2>
            Md Ashiqur Rahman 
             <span class="text-primary"> /√¶ É…™k/ </span> 
             <span id="volumeEmoji" role="button"> üéß </span> 
        </h2>
        <p></p>
        I am Md Ashiqur Rahman, a fourth-year Ph.D. student in Computer Science at Purdue University, guided by Professor Raymond A. Yeh. My research is primarily focused on the development of robust machine learning models, particularly in the areas of equivariance and geometric machine learning, as well as exploring the applications of AI in scientific discovery.
        <p></p>
        I earned my Bachelor's degree in Computer Science and Engineering from the Bangladesh University of Engineering and Technology (BUET). I am passionate about advancing the field of computer science and am always open to discussions and collaborations. Thank you for visiting my page!      
        <p></p>
        <div class="codebox">
            My research unifies geometric principles, signal processing techniques, and equivariance theory to develop more robust and consistent AI systems.
            <p></p> 
            
                <b>Computer Vision:</b> Geometric Deep Learning, Equivariant Neural Networks, Generative Models 
<br />
            
                <b>Operator Learning:</b> Solving PDEs, Scientific Machine Learning 
<br />
            
        </div>
    </div>
</div>

<!-- Affiliations section -->

<hr />

<div class="row" id="affiliations">
    <div class="col">
        <h2 clss="mb-5">üèõÔ∏è Affiliations</h2>
        <p></p>
        <div class="owl-carousel owl-theme affiliations-carousel">
            
                <div class="affiliation-card">
    <div class="affiliation-image-container">
        <img src="assets/img/updates_fig/purdue_logo.png" class="affiliation-image" alt="PhD, Purdue University" />
    </div>
    <div class="affiliation-content">
        <h5 class="affiliation-institution">PhD, Purdue University</h5>
        <p class="affiliation-period">2021 - Present</p>
    </div>
</div>

            
                <div class="affiliation-card">
    <div class="affiliation-image-container">
        <img src="assets/img/updates_fig/autodesk_1.png" class="affiliation-image" alt="Autodesk Research" />
    </div>
    <div class="affiliation-content">
        <h5 class="affiliation-institution">Autodesk Research</h5>
        <p class="affiliation-period">Summer 2025</p>
    </div>
</div>

            
                <div class="affiliation-card">
    <div class="affiliation-image-container">
        <img src="assets/img/updates_fig/Nvidia-Logo.png" class="affiliation-image" alt="NVIDIA Research" />
    </div>
    <div class="affiliation-content">
        <h5 class="affiliation-institution">NVIDIA Research</h5>
        <p class="affiliation-period">Summer 2023</p>
    </div>
</div>

            
                <div class="affiliation-card">
    <div class="affiliation-image-container">
        <img src="assets/img/updates_fig/buet_logo.png" class="affiliation-image" alt="Bangladesh University of Engineering and Technology" />
    </div>
    <div class="affiliation-content">
        <h5 class="affiliation-institution">Bangladesh University of Engineering and Technology</h5>
        <p class="affiliation-period">2015 - 2019</p>
    </div>
</div>

            
        </div>
        <p></p>
    </div>
</div>

<!-- Updates section -->

<hr />

<div class="row" id="updates">
    <div class="col">
        <h2 clss="mb-5">üìú Updates</h2>
        <p></p>
        <div class="owl-carousel owl-theme">
            
                <div class="news-card">
    <img src="assets/img/updates_fig/iccv.png" class="w-full rounded-lg" />
    <div class="news-desc">Two papers accepted at <hightlight>ICCV 2025</hightlight>!</div>
    <div class="news-time">Aug 2025</div>
</div>
            
                <div class="news-card">
    <img src="assets/img/updates_fig/autodesk_1.png" class="w-full rounded-lg" />
    <div class="news-desc">I will spend my summer as AI Research Intern at <hightlight>Autodesk</hightlight>!</div>
    <div class="news-time">May 2025</div>
</div>
            
                <div class="news-card">
    <img src="assets/img/updates_fig/iclr_png_singa.png" class="w-full rounded-lg" />
    <div class="news-desc">I will attend ICLR 2025 in <hightlight>Singapore</hightlight>.</div>
    <div class="news-time">April 2025</div>
</div>
            
                <div class="news-card">
    <img src="assets/img/updates_fig/confernec.png" class="w-full rounded-lg" />
    <div class="news-desc">I will attend NeurIPS 2024 in <hightlight>Vancouver, Canada</hightlight>.</div>
    <div class="news-time">December 2024</div>
</div>
            
        </div>
        <p></p>
    </div>
</div>

<!-- Research section -->

<hr />

<div class="row" id="research">
    <div class="col">
        <h2 clss="mb-5">üìö Publications</h2>
        <p></p>
        <div id="filters-project">
            <button class="filter-button active" data-filter="*">all</button>
            
                <button class="filter-button" data-filter="Equivariance">Equivariance</button>
            
                <button class="filter-button" data-filter="Neural Operator">Neural Operator</button>
            
                <button class="filter-button" data-filter="Bioinformatics">Bioinformatics</button>
            
        </div>
        <p></p>
        <div id="projects" class="isotope">
            
                <div class="project publication-card" data-filter="Equivariance">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/paper_fig/clip_sym.png" />
        </div>
        <div class="col-sm-8">
            <div class="publication-content">
                <div class="publication-header">
                    
                    <h4 class="publication-title">CLIPSym: Delving into Symmetry Detection with CLIP</h4>
                </div>
                
                <div class="publication-meta">
                    <i><a href="" target="_blank" rel="noopener" class="conference-link">ICCV 2025</a></i> 
                    
                </div>
                
                <div class="publication-authors">Tinghan Yang, <u>Md Ashiqur Rahman</u>, Raymond A. Yeh</div>
                
                <div class="publication-links">
                     <a href="https://arxiv.org/pdf/2508.14197" target="_blank" rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a> 
                     <a href="https://github.com/timyoung2333/CLIPSym" target="_blank" rel="noopener" class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a> 
                    
                    
                    
                    
                    
                    
                </div>
                
                <div class="publication-abstract">
                    <span class="abstract-label">Abstract:</span> 
                    Symmetry is one of the most fundamental geometric cues in computer vision, and detecting it has been an ongoing challenge.
                    <span class="collapse" id="more_equivariance">
                        With the recent advances in vision-language models,~i.e., CLIP, we investigate whether a pre-trained CLIP model can aid symmetry detection by leveraging the additional symmetry cues found in the natural image descriptions. We propose CLIPSym, which leverages CLIP's image and language encoders and a rotation-equivariant decoder based on a hybrid of Transformer and G-Convolution to detect rotation and reflection symmetries. To fully utilize CLIP's language encoder, we have developed a novel prompting technique called Semantic-Aware Prompt Grouping (SAPG), which aggregates a diverse set of frequent object-based prompts to better integrate the semantic cues for symmetry detection. Empirically, we show that CLIPSym outperforms the current state-of-the-art on three standard symmetry detection datasets (DENDI, SDRW, and LDRS). Finally, we conduct detailed ablations verifying the benefits of CLIP's pre-training, the proposed equivariant decoder, and the SAPG technique.
                    </span> 
                    <span> <a href="#more_equivariance" data-toggle="collapse" onclick="toggleText(this)" id="link-more_equivariance" class="abstract-toggle">... See More</a></span>
                </div>
            </div>
        </div>                       
    </div>
</div>

            
                <div class="project publication-card" data-filter="Equivariance">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/paper_fig/local_scale_logo.png" />
        </div>
        <div class="col-sm-8">
            <div class="publication-content">
                <div class="publication-header">
                    
                    <h4 class="publication-title">Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer</h4>
                </div>
                
                <div class="publication-meta">
                    <i><a href="" target="_blank" rel="noopener" class="conference-link">ICCV 2025</a></i> 
                    
                </div>
                
                <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Chiao-An Yang, Michael N. Cheng, Lim Jun Hao, Jeremiah Jiang, Teck-Yian Lim, Raymond A. Yeh</div>
                
                <div class="publication-links">
                     <a href="https://arxiv.org/pdf/2508.14187" target="_blank" rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a> 
                     <a href="https://github.com/ashiq24/local-scale-equivariance" target="_blank" rel="noopener" class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a> 
                     <a href="https://ashiq24.github.io/local-scale-equivariance/" target="_blank" rel="noopener" class="btn-link btn-website"><i class="fas fa-external-link-alt"></i> WEBSITE</a> 
                    
                    
                    
                    
                    
                </div>
                
                <div class="publication-abstract">
                    <span class="abstract-label">Abstract:</span> 
                    Scale variation is a fundamental challenge in computer vision. Objects of the same class can have different sizes
                    <span class="collapse" id="more_equivariance">
                        and their perceived size is further affected by the distance from the camera. These variations are local to the objects, i.e., different object sizes may change differently within the same image. To effectively handle scale variations, we present a deep equilibrium canonicalizer (DEC) to improve the local scale equivariance of a model. DEC can be easily incorporated into existing network architectures and can be adapted to a pre-trained model. Notably, we show that on the competitive ImageNet benchmark, DEC improves both model performance and local scale consistency across four popular pre-trained deep-nets, e.g., ViT, DeiT, Swin, and BEiT.
                    </span> 
                    <span> <a href="#more_equivariance" data-toggle="collapse" onclick="toggleText(this)" id="link-more_equivariance" class="abstract-toggle">... See More</a></span>
                </div>
            </div>
        </div>                       
    </div>
</div>

            
                <div class="project publication-card" data-filter="Equivariance">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/paper_fig/group_dwn.jpg" />
        </div>
        <div class="col-sm-8">
            <div class="publication-content">
                <div class="publication-header">
                    
                    <h4 class="publication-title">Group Downsampling with Equivariant Anti-aliasing</h4>
                </div>
                
                <div class="publication-meta">
                    <i><a href="" target="_blank" rel="noopener" class="conference-link">ICLR 2025</a></i> 
                    
                </div>
                
                <div class="publication-authors"><u>Md Ashiqur Rahman</u>, and Raymond A. Yeh.</div>
                
                <div class="publication-links">
                     <a href="https://openreview.net/pdf?id=sOte83GogU" target="_blank" rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a> 
                     <a href="https://github.com/ashiq24/Group_Sampling" target="_blank" rel="noopener" class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a> 
                    
                     <a href="https://colab.research.google.com/drive/1Fkuid94wnVltsgwOblvbuGaVMjLl1YCr?usp=sharing" target="_blank" rel="noopener" class="btn-link btn-demo"><i class="fas fa-play-circle"></i> DEMO</a> 
                    
                    
                    
                     <a href="https://huggingface.co/blog/ashiq24/group-sampling" target="_blank" rel="noopener" class="btn-link btn-tutorial"><i class="fas fa-book-open"></i> TUTORIAL</a> 
                </div>
                
                <div class="publication-abstract">
                    <span class="abstract-label">Abstract:</span> 
                    Downsampling layers are crucial building blocks in CNN architectures, which help to increase the receptive field for learning high-level features and reduce the amount of memory/computation in the model.
                    <span class="collapse" id="more_equivariance">
                        In this work, we study the generalization of the uniform downsampling layer for group equivariant architectures, e.g., $G$-CNNs. That is, we aim to downsample signals (feature maps) on general finite groups with anti-aliasing. This involves the following (a) Given a finite group and a downsampling rate, we present an algorithm to form a suitable choice of subgroup. (b) Given a group and a subgroup, we study the notion of bandlimited-ness and propose how to perform anti-aliasing. Notably, our method generalizes the notion of downsampling based on classical sampling theory. When the signal is on a cyclic group, i.e., periodic, our method recovers the standard downsampling of an ideal low-pass filter followed by a subsampling operation. Finally, we conducted experiments on image classification tasks demonstrating that the proposed downsampling operation improves accuracy, better preserves equivariance, and reduces model size when incorporated into $G$-equivariant networks.
                    </span> 
                    <span> <a href="#more_equivariance" data-toggle="collapse" onclick="toggleText(this)" id="link-more_equivariance" class="abstract-toggle">... See More</a></span>
                </div>
            </div>
        </div>                       
    </div>
</div>

            
                <div class="project publication-card" data-filter="Neural Operator">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/paper_fig/codano.png" />
        </div>
        <div class="col-sm-8">
            <div class="publication-content">
                <div class="publication-header">
                    
                    <h4 class="publication-title">Pretraining Codomain Attention Neural Operators for Solving Multiphysics PDEs.</h4>
                </div>
                
                <div class="publication-meta">
                    <i><a href="" target="_blank" rel="noopener" class="conference-link">NeurIPS 2024</a></i> 
                    
                </div>
                
                <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Robert Joseph George, Mogab Elleithy, Daniel Leibovici, Zongyi Li, Boris Bonev, Colin White, Julius Berner, Raymond A. Yeh, Jean Kossaifi, Kamyar Azizzadenesheli, Anima Anandkumar</div>
                
                <div class="publication-links">
                     <a href="https://arxiv.org/pdf/2403.12553" target="_blank" rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a> 
                     <a href="https://github.com/neuraloperator/CoDA-NO" target="_blank" rel="noopener" class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a> 
                    
                     <a href="https://colab.research.google.com/drive/1W6Qy5Mk_vEjZgrA0tWMespXqKEYDOdc6?usp=sharing" target="_blank" rel="noopener" class="btn-link btn-demo"><i class="fas fa-play-circle"></i> DEMO</a> 
                    
                    
                    
                    
                </div>
                
                <div class="publication-abstract">
                    <span class="abstract-label">Abstract:</span> 
                    Existing neural operator architectures face challenges when solving multiphysics problems with coupled partial differential equations (PDEs), due to complex geometries,
                    <span class="collapse" id="more_neural_operator">
                        interactions between physical variables, and the lack of large amounts of high-resolution training data. To address these issues, we propose Codomain Attention Neural Operator (CoDA-NO), which tokenizes functions along the codomain or channel space, enabling self-supervised learning or pretraining of multiple PDE systems. Specifically, we extend positional encoding, self-attention, and normalization layers to the function space. CoDA-NO can learn representations of different PDE systems with a single model. We evaluate CoDA-NO's potential as a backbone for learning multiphysics PDEs over multiple systems by considering few-shot learning settings. On complex downstream tasks with limited data, such as fluid flow simulations and fluid-structure interactions, we found CoDA-NO to outperform existing methods on the few-shot learning task by over 36%.
                    </span> 
                    <span> <a href="#more_neural_operator" data-toggle="collapse" onclick="toggleText(this)" id="link-more_neural_operator" class="abstract-toggle">... See More</a></span>
                </div>
            </div>
        </div>                       
    </div>
</div>

            
                <div class="project publication-card" data-filter="Equivariance">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/paper_fig/scale_eq.png" />
        </div>
        <div class="col-sm-8">
            <div class="publication-content">
                <div class="publication-header">
                    
                    <h4 class="publication-title">Truly Scale-Equivariant Deep Nets with Fourier Layers.</h4>
                </div>
                
                <div class="publication-meta">
                    <i><a href="" target="_blank" rel="noopener" class="conference-link">NeurIPS 2023</a></i> 
                    
                </div>
                
                <div class="publication-authors"><u>Md Ashiqur Rahman</u>, and Raymond A. Yeh.</div>
                
                <div class="publication-links">
                     <a href="https://arxiv.org/pdf/2311.02922" target="_blank" rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a> 
                     <a href="https://github.com/ashiq24/Scale_Equivarinat_Fourier_Layer/" target="_blank" rel="noopener" class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a> 
                    
                     <a href="https://colab.research.google.com/drive/1fKHxYw1QxJ1CWpDFGLdl8Im83GnfAbFC?usp=sharing" target="_blank" rel="noopener" class="btn-link btn-demo"><i class="fas fa-play-circle"></i> DEMO</a> 
                    
                    
                     <a href="https://ashiq24.github.io/scale_equivariant_fourier_layer/resource/poster_thumb.pdf" target="_blank" rel="noopener" class="btn-link btn-poster"><i class="fas fa-image"></i> POSTER</a> 
                    
                </div>
                
                <div class="publication-abstract">
                    <span class="abstract-label">Abstract:</span> 
                    In computer vision, models must be able to adapt to changes in image resolution to effectively carry out tasks such as image segmentation
                    <span class="collapse" id="more_equivariance">
                        ; This is known as scale-equivariance. Recent works have made progress in developing scale-equivariant convolutional neural networks, e.g., through weight-sharing and kernel resizing. However, these networks are not truly scale-equivariant in practice. Specifically, they do not consider anti-aliasing as they formulate the down-scaling operation in the continuous domain. To address this shortcoming, we directly formulate down-scaling in the discrete domain with consideration of anti-aliasing. We then propose a novel architecture based on Fourier layers to achieve truly scale-equivariant deep nets, i.e., absolute zero equivariance-error. Following prior works, we test this model on MNIST-scale and STL-10 datasets. Our proposed model achieves competitive classification performance while maintaining zero equivariance-error.
                    </span> 
                    <span> <a href="#more_equivariance" data-toggle="collapse" onclick="toggleText(this)" id="link-more_equivariance" class="abstract-toggle">... See More</a></span>
                </div>
            </div>
        </div>                       
    </div>
</div>

            
                <div class="project publication-card" data-filter="Neural Operator">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/paper_fig/uno.png" />
        </div>
        <div class="col-sm-8">
            <div class="publication-content">
                <div class="publication-header">
                    
                    <h4 class="publication-title">U-NO: U-shaped Neural Operators</h4>
                </div>
                
                <div class="publication-meta">
                    <i><a href="" target="_blank" rel="noopener" class="conference-link">Transactions on Machine Learning Research 2023</a></i> 
                    
                </div>
                
                <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Zachary E. Ross, Kamyar Azizzadenesheli.</div>
                
                <div class="publication-links">
                     <a href="https://openreview.net/pdf?id=j3oQF9coJd" target="_blank" rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a> 
                     <a href="https://github.com/ashiq24/UNO" target="_blank" rel="noopener" class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a> 
                    
                     <a href="https://colab.research.google.com/drive/1f1WYsjAgIjJRFtfQYYnZCZsxl602MMPX?usp=sharing" target="_blank" rel="noopener" class="btn-link btn-demo"><i class="fas fa-play-circle"></i> DEMO</a> 
                    
                    
                    
                    
                </div>
                
                <div class="publication-abstract">
                    <span class="abstract-label">Abstract:</span> 
                    Neural operators generalize classical neural networks to maps between infinite-dimensional spaces, e.g., function spaces.
                    <span class="collapse" id="more_neural_operator">
                        Prior works on neural operators proposed a series of novel methods to learn such maps and demonstrated unprecedented success in learning solution operators of partial differential equations. Due to their close proximity to fully connected architectures, these models mainly suffer from high memory usage and are generally limited to shallow deep learning models. In this paper, we propose U-shaped Neural Operator (U-NO), a U-shaped memory enhanced architecture that allows for deeper neural operators. U-NOs exploit the problem structures in function predictions and demonstrate fast training, data efficiency, and robustness with respect to hyperparameters choices. We study the performance of U-NO on PDE benchmarks, namely, Darcy's flow law and the Navier-Stokes equations. We show that U-NO results in an average of 26% and 44% prediction improvement on Darcy's flow and turbulent Navier-Stokes equations, respectively, over the state of the art. On Navier-Stokes 3D spatiotemporal operator learning task, we show U-NO provides 37\% improvement over the state of art methods.
                    </span> 
                    <span> <a href="#more_neural_operator" data-toggle="collapse" onclick="toggleText(this)" id="link-more_neural_operator" class="abstract-toggle">... See More</a></span>
                </div>
            </div>
        </div>                       
    </div>
</div>

            
                <div class="project publication-card" data-filter="Neural Operator">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/paper_fig/gano.jpg" />
        </div>
        <div class="col-sm-8">
            <div class="publication-content">
                <div class="publication-header">
                    
                    <h4 class="publication-title">Generative Adversarial Neural Operators.</h4>
                </div>
                
                <div class="publication-meta">
                    <i><a href="" target="_blank" rel="noopener" class="conference-link">Transactions on Machine Learning Research 2022</a></i> 
                    
                </div>
                
                <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Manuel A. Florez, Anima Anandkumar, Zachary E. Ross, Kamyar Azizzadenesheli.</div>
                
                <div class="publication-links">
                     <a href="https://openreview.net/pdf?id=X1VzbBU6xZ" target="_blank" rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a> 
                     <a href="https://github.com/neuraloperator/GANO" target="_blank" rel="noopener" class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a> 
                    
                    
                    
                    
                    
                    
                </div>
                
                <div class="publication-abstract">
                    <span class="abstract-label">Abstract:</span> 
                    We propose the generative adversarial neural operator (GANO), a generative model paradigm for learning probabilities on infinite-dimensional function spaces.
                    <span class="collapse" id="more_neural_operator">
                        The natural sciences and engineering are known to have many types of data that are sampled from infinite-dimensional function spaces, where classical finite-dimensional deep generative adversarial networks (GANs) may not be directly applicable. GANO generalizes the GAN framework and allows for the sampling of functions by learning push-forward operator maps in infinite-dimensional spaces. GANO consists of two main components, a generator neural operator and a discriminator neural functional. The inputs to the generator are samples of functions from a user-specified probability measure, e.g., Gaussian random field (GRF), and the generator outputs are synthetic data functions. The input to the discriminator is either a real or synthetic data function. In this work, we instantiate GANO using the Wasserstein criterion and show how the Wasserstein loss can be computed in infinite-dimensional spaces. We empirically study GANO in controlled cases where both input and output functions are samples from GRFs and compare its performance to the finite-dimensional counterpart GAN. We empirically study the efficacy of GANO on real-world function data of volcanic activities and show its superior performance over GAN.
                    </span> 
                    <span> <a href="#more_neural_operator" data-toggle="collapse" onclick="toggleText(this)" id="link-more_neural_operator" class="abstract-toggle">... See More</a></span>
                </div>
            </div>
        </div>                       
    </div>
</div>

            
                <div class="project publication-card" data-filter="Neural Operator">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/paper_fig/pacmo.jpg" />
        </div>
        <div class="col-sm-8">
            <div class="publication-content">
                <div class="publication-header">
                    
                    <h4 class="publication-title">PaCMO: Partner Dependent Human Motion Generation in Dyadic Human Activity using Neural Operators.</h4>
                </div>
                
                <div class="publication-meta">
                    <i><a href="" target="_blank" rel="noopener" class="conference-link">ArXiv 2022</a></i> 
                    
                </div>
                
                <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Jasorsi Ghosh, Hrishikesh Viswanath, Kamyar Azizzadenesheli, Aniket Bera.</div>
                
                <div class="publication-links">
                     <a href="https://arxiv.org/pdf/2211.16210" target="_blank" rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a> 
                    
                    
                    
                    
                    
                    
                    
                </div>
                
                <div class="publication-abstract">
                    <span class="abstract-label">Abstract:</span> 
                    We address the problem of generating 3D human motions in dyadic activities. In contrast to the concurrent works, which mainly focus on
                    <span class="collapse" id="more_neural_operator">
                        generating the motion of a single actor from the textual description, we generate the motion of one of the actors from the motion of the other participating actor in the action. This is a particularly challenging, under-explored problem, that requires learning intricate relationships between the motion of two actors participating in an action and also identifying the action from the motion of one actor. To address these, we propose partner conditioned motion operator (PaCMO), a neural operator-based generative model which learns the distribution of human motion conditioned by the partner's motion in function spaces through adversarial training. Our model can handle long unlabeled action sequences at arbitrary time resolution. We also introduce the "Functional Frechet Inception Distance" (F2ID) metric for capturing similarity between real and generated data for function spaces. We test PaCMO on NTU RGB+D and DuetDance datasets and our model produces realistic results evidenced by the F2ID score and the conducted user study.
                    </span> 
                    <span> <a href="#more_neural_operator" data-toggle="collapse" onclick="toggleText(this)" id="link-more_neural_operator" class="abstract-toggle">... See More</a></span>
                </div>
            </div>
        </div>                       
    </div>
</div>

            
                <div class="project publication-card" data-filter="Bioinformatics">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/paper_fig/beene.jpeg" />
        </div>
        <div class="col-sm-8">
            <div class="publication-content">
                <div class="publication-header">
                    
                    <h4 class="publication-title">BEENE: Deep Learning-based Nonlinear Embedding Improves Batch Effect Estimation.BEENE: Deep Learning-based Nonlinear Embedding Improves Batch Effect Estimation.</h4>
                </div>
                
                <div class="publication-meta">
                    <i><a href="https://academic.oup.com/bioinformatics" target="_blank" rel="noopener" class="conference-link">Bioinformatics, Volume 39, 2023</a></i> 
                    
                </div>
                
                <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Abdullah Aman Tutul, Mahfuza Sharmin, Md Shamsuzzoha Bayzid</div>
                
                <div class="publication-links">
                     <a href="https://academic.oup.com/bioinformatics/article/39/8/btad479/7240486?login=false" target="_blank" rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a> 
                     <a href="https://github.com/ashiq24/BEENE" target="_blank" rel="noopener" class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a> 
                    
                    
                    
                    
                    
                    
                </div>
                
                <div class="publication-abstract">
                    <span class="abstract-label">Abstract:</span> 
                    Analyzing large-scale single-cell transcriptomic datasets generated using different technologies is challenging due to the presence of batch-specific systematic variations known as batch effects.
                    <span class="collapse" id="more_bioinformatics">
                        Since biological and technological differences are often interspersed, detecting and accounting for batch effects in RNA-seq datasets are critical for effective data integration and interpretation. Low-dimensional embeddings, such as principal component analysis (PCA) are widely used in visual inspection and estimation of batch effects. Linear dimensionality reduction methods like PCA are effective in assessing the presence of batch effects, especially when batch effects exhibit linear patterns. However, batch effects are inherently complex and existing linear dimensionality reduction methods could be inadequate and imprecise in the presence of sophisticated nonlinear batch effects. Results:- We present Batch Effect Estimation using Nonlinear Embedding (BEENE), a deep nonlinear auto-encoder network which is specially tailored to generate an alternative lower dimensional embedding suitable for both linear and nonlinear batch effects. BEENE simultaneously learns the batch and biological variables from RNA-seq data, resulting in an embedding that is more robust and sensitive than PCA embedding in terms of detecting and quantifying batch effects. BEENE was assessed on a collection of carefully controlled simulated datasets as well as biological datasets, including two technical replicates of mouse embryogenesis cells, peripheral blood mononuclear cells from three largely different experiments and five studies of pancreatic islet cells
                    </span> 
                    <span> <a href="#more_bioinformatics" data-toggle="collapse" onclick="toggleText(this)" id="link-more_bioinformatics" class="abstract-toggle">... See More</a></span>
                </div>
            </div>
        </div>                       
    </div>
</div>

            
                <div class="project publication-card" data-filter="Bioinformatics">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/paper_fig/chapao.jpg" />
        </div>
        <div class="col-sm-8">
            <div class="publication-content">
                <div class="publication-header">
                    
                    <h4 class="publication-title">CHAPAO: Likelihood and hierarchical reference-based representation of biomolecular sequences and applications to compressing multiple sequence alignments.</h4>
                </div>
                
                <div class="publication-meta">
                    <i><a href="https://journals.plos.org/plosone/" target="_blank" rel="noopener" class="conference-link">PLOS ONE 2022</a></i> 
                    
                </div>
                
                <div class="publication-authors"><u>Md Ashiqur Rahman</u>, Abdullah Aman Tutul, Sifat Muhammad Abdullah, Md. Shamsuzzoha Bayzid.</div>
                
                <div class="publication-links">
                     <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0265360" target="_blank" rel="noopener" class="btn-link btn-pdf"><i class="fas fa-file-pdf"></i> PDF</a> 
                     <a href="https://github.com/ashiq24/CHAPAO" target="_blank" rel="noopener" class="btn-link btn-code"><i class="fab fa-github"></i> CODE</a> 
                    
                    
                    
                    
                    
                    
                </div>
                
                <div class="publication-abstract">
                    <span class="abstract-label">Abstract:</span> 
                    High-throughput experimental technologies are generating tremendous amounts of genomic data, offering valuable resources to answer important questions and extract biological insights. Storing this sheer amount of genomic data has become a major concern in bioinformatics.
                    <span class="collapse" id="more_bioinformatics">
                        General purpose compression techniques (e.g. gzip, bzip2, 7-zip) are being widely used due to their pervasiveness and relatively good speed. However, they are not customized for genomic data and may fail to leverage special characteristics and redundancy of the biomolecular sequences. Results:- We present a new lossless compression method CHAPAO (COmpressing Alignments using Hierarchical and Probabilistic Approach), which is especially designed for multiple sequence alignments (MSAs) of biomolecular data and offers very good compression gain. We have introduced a novel hierarchical referencing technique to represent biomolecular sequences which combines likelihood based analyses of the sequence similarities and graph theoretic algorithms. We performed an extensive evaluation study using a collection of real biological data from the avian phylogenomics project, 1000 plants project (1KP), and 16S and 23S rRNA datasets. We report the performance of CHAPAO in comparison with general purpose compression techniques as well as with MFCompress and Nucleotide Archival Format (NAF)‚Äîtwo of the best known methods especially designed for FASTA files. Experimental results suggest that CHAPAO offers significant improvements in compression gain over most other alternative methods.
                    </span> 
                    <span> <a href="#more_bioinformatics" data-toggle="collapse" onclick="toggleText(this)" id="link-more_bioinformatics" class="abstract-toggle">... See More</a></span>
                </div>
            </div>
        </div>                       
    </div>
</div>

            
        </div>
        <p></p>
    </div>
</div>

<!-- Outreach section

<hr>
<div class="row" id="outreach">
    <div class="col">
        <h2 clss="mb-5">üß© Outreach Activities</h2>
        <p></p>
        
        <p></p>
    </div>
</div> -->

<!-- Resources section -->

<hr />

<div class="row" id="resources">
    <div class="col">
        <h2 clss="mb-5">‚õèÔ∏è Resources</h2>
        <p></p>
        all software releases of the above projects can also be found here!
        <p></p>
        <div id="filters-resources">
            <button class="filter-button active" data-filter="*">all</button>
            
                <button class="filter-button" data-filter="research">research</button>
            
                <button class="filter-button" data-filter="misc">miscellaneous</button>
            
                <button class="filter-button" data-filter="Open Source">open-source</button>
            
        </div>
        <p></p>
        <div id="github-cards" class="isotope">
            
                <div class="github-card" data-filter="research">
    <div data-url="https://api.github.com/repos/neuraloperator/CoDA-NO"></div>
</div>

            
                <div class="github-card" data-filter="open-source">
    <div data-url="https://api.github.com/repos/neuraloperator/neuraloperator"></div>
</div>

            
                <div class="github-card" data-filter="research">
    <div data-url="https://api.github.com/repos/ashiq24/Scale_Equivarinat_Fourier_Layer"></div>
</div>

            
                <div class="github-card" data-filter="research">
    <div data-url="https://api.github.com/repos/ashiq24/UNO"></div>
</div>

            
                <div class="github-card" data-filter="research">
    <div data-url="https://api.github.com/repos/ashiq24/BEENE"></div>
</div>

            
                <div class="github-card" data-filter="open-source">
    <div data-url="https://api.github.com/repos/ashiq24/Copula"></div>
</div>

            
                <div class="github-card" data-filter="miscellaneous">
    <div data-url="https://api.github.com/repos/ashiq24/Python-Tool-to-Visualize-Fractals"></div>
</div>

            
        </div>
        <p></p>
    </div>
</div>

<!-- Gallery section -->

<!-- <hr>
<div class="row" id="gallery">
    <div class="col">
        <h2 clss="mb-5">üñºÔ∏è Gallery</h2>
        <p></p>
        
        <p></p>
        
        <p></p>
    </div>
</div> -->

<!-- Footer section -->

<div>‚Äé</div>
<footer class="pt-2 my-md-2 pt-md-">
    <div class="row justify-content-center">
        <div class="col-7 col-md text-left align-self-center">
            <p class="h6">¬© Md Ashiqur Rahman, 2025</p>
            <a href="https://github.com/mkhangg/academic-website" target="_blank" rel="noopener"><b>&gt; web source @github</b></a>
        </div>
        <div class="col col-md text-right">
            <div class="footer-logos">
                
            </div>
        </div>
    </div>
    <p></p>
</footer>


        </div>

        <!-- Bootstrap core JS-->
        <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.bundle.min.js"></script>

        <!-- Isotope JS -->
        <script src="https://cdn.jsdelivr.net/npm/isotope-layout@3.0.2/dist/isotope.pkgd.min.js"></script>

        <!-- OwlCarousel2 JS -->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/owl.carousel.min.js"></script>

        <!-- Axios JS -->
        <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>

		<!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js"></script>

		<!-- Core theme JS-->
        <script src="js/scripts.js"></script>

    </body>
</html>
